{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tesi03.ipynb","provenance":[{"file_id":"1MEFnc5wISBQxX9jAyp73yML3DjhLmhJo","timestamp":1647736665400}],"collapsed_sections":[],"authorship_tag":"ABX9TyN+M5nuV1iq/k8dmDMORoyW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19639,"status":"ok","timestamp":1648150578630,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"},"user_tz":-60},"id":"AvgTUNhILrw9","outputId":"2c8a8c08-ce73-4e85-f236-e99f3f26d6d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","\n","SEED = 1234\n","tf.random.set_seed(SEED)\n","\n","cwd = os.getcwd() #get current working directory\n","#physical_devices = tf.config.list_physical_devices('GPU') \n","physical_devices = tf.config.list_physical_devices('CPU') \n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#!pip install git+https://github.com/rstrudel/segmenter.git\n","#!pip install ."],"metadata":{"id":"9MGP4zQ6qnW_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!pip install --ignore-installed PyYAML "],"metadata":{"id":"NxmQTJAR6ly0","executionInfo":{"status":"ok","timestamp":1648058144046,"user_tz":-60,"elapsed":7486,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"da40954e-745d-43e0-e30b-1c09d2398628"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyYAML\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 5.5 MB/s \n","\u001b[?25hInstalling collected packages: PyYAML\n","Successfully installed PyYAML-6.0\n"]}]},{"cell_type":"markdown","source":["From https://blog.tensorflow.org/2018/07/an-introduction-to-biomedical-image-analysis-tensorflow-dltk.html\n","\n","Using a TFRecords database: For most deep learning problems on image volumes, the database of training examples is too large to fit into memory. The TFRecords format allows to serialise training examples and store them on disk with quick write access (i.e. parallel data reads):"],"metadata":{"id":"eeoSO655e6Mk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60329,"status":"ok","timestamp":1648055336602,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"},"user_tz":-60},"id":"BpVcRhwLMQy-","outputId":"d58252d9-1513-4074-83bb-cdab1e748811"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Unzipped\n","Archive:  /content/drive/My Drive/Dataset/brats2019_slice_testing_tfrecords.zip\n","replace brats2019_slice_testing_tfrecords/brats2019_slice_testing.tfrecords? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n","Archive:  /content/drive/My Drive/Dataset/brats2019_slice_training_tfrecords.zip\n","replace brats2019_slice_training_tfrecords/brats2019_slice_training.tfrecords? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n","Archive:  /content/drive/My Drive/Dataset/brats2019_slice_validation_tfrecords.zip\n","replace brats2019_slice_validation_tfrecords/brats2019_slice_validation.tfrecords? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}],"source":["#!mkdir -p '/content/drive/My Drive/Unzipped'\n","#%cd '/content/drive/My Drive/Unzipped' \n","#!unzip '/content/drive/My Drive/Dataset/brats2019_slice_testing_tfrecords' \n","#!unzip '/content/drive/My Drive/Dataset/brats2019_slice_training_tfrecords' \n","#!unzip '/content/drive/My Drive/Dataset/brats2019_slice_validation_tfrecords' "]},{"cell_type":"markdown","source":["# RUNNING\n"],"metadata":{"id":"B3gLw-AEIwyP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NeQCvuV0FGUG"},"outputs":[],"source":["#if you want to clone the repo\n","#!git clone https://github.com/rstrudel/segmenter.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsLR3mSFBoE5"},"outputs":[],"source":["#%cd /content/drive/My Drive/Segmenter/segmenter\n","\n"]},{"cell_type":"markdown","source":["Col codice che segue vorremmo prendere i file di tipo tfrecords e decodificarli per ottenerne le immagini.\n","Le colormaps si possono trovare al sito https://scipy-cookbook.readthedocs.io/items/Matplotlib_Show_colormaps.html\n"],"metadata":{"id":"RN1PR-fXfs1b"}},{"cell_type":"code","source":["#!pip install tensorflow tensorflow_addons pillow numpy matplotlib"],"metadata":{"id":"wPRrwMjLgWFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","import numpy as np\n","\n","#dataset_folder = os.path.join(cwd, \"drive/My Drive/Unzipped/\");\n","#dataset_name = os.path.join(dataset_folder, \"brats2019_slice_training_tfrecords/brats2019_slice_training.tfrecords\")\n","dataset_name = os.path.join('/content/drive/My Drive/Unzipped/', \"brats2019_slice_training_tfrecords/brats2019_slice_training.tfrecords\")\n","raw_dataset = tf.data.TFRecordDataset(dataset_name)\n","raw_dataset \n","for raw_record in raw_dataset.take(10): #per capire la struttura del file tfrecord\n","    example = tf.train.Example()\n","    example.ParseFromString(raw_record.numpy())\n","    #print(example)\n","    #print(repr(raw_record))\n","\n","\n","    parsed = tf.train.Example.FromString(raw_record.numpy())\n","    feature = parsed.features.feature\n","\n","    raw_img_flair_mri = feature['flair_mri'].bytes_list.value[0]\n","    raw_img_seg = feature['seg'].bytes_list.value[0]\n","    raw_img_t1_mri = feature['t1_mri'].bytes_list.value[0]\n","    raw_img_t1ce_mri = feature['t1ce_mri'].bytes_list.value[0]\n","    raw_img_t2_mri = feature['t2_mri'].bytes_list.value[0]\n","\n","    img_flair_mri = tf.image.decode_png(raw_img_flair_mri)\n","    img_t1_mri = tf.image.decode_png(raw_img_t1_mri)\n","    img_t1ce_mri = tf.image.decode_png(raw_img_t1ce_mri)\n","    img_t2_mri = tf.image.decode_png(raw_img_t2_mri)\n","    img_seg = tf.image.decode_png(raw_img_seg)\n","\n","    f, splt = plt.subplots(1,5, figsize = (25.0, 25.0)) \n","\n","    \n","    splt[0].imshow(tf.squeeze(img_flair_mri), cmap='jet', vmin=0, vmax=255)\n","    splt[1].imshow(tf.squeeze(img_t1_mri), cmap='jet')\n","    splt[2].imshow(tf.squeeze(img_t2_mri), cmap='jet')\n","    splt[3].imshow(tf.squeeze(img_t1ce_mri), cmap='jet')\n","    splt[4].imshow(tf.squeeze(img_seg), cmap='jet')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1uA3iCBZAKMlGs-8CU1xpAyNTqWu_XwUv"},"id":"8BLp1_vBpO1S","executionInfo":{"status":"ok","timestamp":1648150835739,"user_tz":-60,"elapsed":10028,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"}},"outputId":"57e8188a-eb81-4ea0-9dd5-8efc1fea8749"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["A questo punto abbiamo le risonanze magnetiche in formato di immagini. Dobbiamo però ancora\n","- mettere queste immagini in dei tensori\n","- capire come dare in pasto queste immagini al segmenter \n","  - NB: il segmenter accetta immagini a 3 canali, una per ogni colore, mentre noi qua abbiamo 4 immagini ad un canale ciascuna. Come gestiamo questo problema?\n","    - idea: una patch a 3 canali, prima di essere data in pasto all'encoder del transformer, viene comunque \"appiattita\" (flattened). Quindi, potremmo fare finta che le 4 \"viste\" della RM siano i canali, e invece di avere 3 canali ne abbiamo 4. A livello matematico non cambia nulla. Però: come modificare il segmenter per fare in modo che ciò sia possibile?\n","- ammesso che riusciamo ad utilizzare il segmenter per fare ciò: come facciamo poi a fare fine tuning? "],"metadata":{"id":"mT7BpHDVxb4q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0oK8pwWODkc"},"outputs":[],"source":["#!python -m segm.inference --model-path \"/content/drive/My Drive/Models/Pre-trained/PASCAL - Seg-L-Mask16/checkpoint.pth\" -i images/ -o segmaps/"]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Segmenter/segmenter\n","\n","#!export DATASET='/content/drive/My Drive/Immagine/'\n","!pip install .\n","!pip install --ignore-installed PyYAML "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gM4VXshM1C88","executionInfo":{"status":"ok","timestamp":1648154441247,"user_tz":-60,"elapsed":56939,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"}},"outputId":"fed2962b-45dd-4ea1-9a88-c5a6bd28a560"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Segmenter/segmenter\n","Processing /content/drive/My Drive/Segmenter/segmenter\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from segm==0.0.1) (1.10.0+cu111)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from segm==0.0.1) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from segm==0.0.1) (1.21.5)\n","Collecting einops\n","  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n","Collecting python-hostlist\n","  Downloading python-hostlist-1.21.tar.gz (35 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from segm==0.0.1) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from segm==0.0.1) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from segm==0.0.1) (6.0)\n","Collecting timm==0.4.12\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 12.7 MB/s \n","\u001b[?25hCollecting mmcv==1.3.8\n","  Downloading mmcv-1.3.8.tar.gz (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 69.6 MB/s \n","\u001b[?25hCollecting mmsegmentation==0.14.1\n","  Downloading mmsegmentation-0.14.1-py3-none-any.whl (201 kB)\n","\u001b[K     |████████████████████████████████| 201 kB 68.8 MB/s \n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv==1.3.8->segm==0.0.1) (7.1.2)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 72.0 MB/s \n","\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.14.1->segm==0.0.1) (3.2.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.14.1->segm==0.0.1) (3.2.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.4.12->segm==0.0.1) (0.11.1+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->segm==0.0.1) (3.10.0.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.14.1->segm==0.0.1) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.14.1->segm==0.0.1) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.14.1->segm==0.0.1) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.14.1->segm==0.0.1) (1.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmsegmentation==0.14.1->segm==0.0.1) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.14.1->segm==0.0.1) (0.2.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.14.1->segm==0.0.1) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->mmsegmentation==0.14.1->segm==0.0.1) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->segm==0.0.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->segm==0.0.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->segm==0.0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->segm==0.0.1) (3.0.4)\n","Building wheels for collected packages: segm, mmcv, python-hostlist\n","  Building wheel for segm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segm: filename=segm-0.0.1-py3-none-any.whl size=1898 sha256=8f5b146ba42c51e3baec8bef502ff82d11dba5ac58c4ed206465551b800d6ab4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-iur77tmk/wheels/69/a6/f5/fedc521f36addf1abc849d46e38485fba3ad8d9a081418b659\n","  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mmcv: filename=mmcv-1.3.8-py2.py3-none-any.whl size=451081 sha256=dd823908794aa076bfd363f4254442813bac70a2be1636d2dd793ab948823922\n","  Stored in directory: /root/.cache/pip/wheels/ca/af/64/171ef1b8d373baa2fec34ac1a417c62ec06a49a56bbde7f3a3\n","  Building wheel for python-hostlist (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-hostlist: filename=python_hostlist-1.21-py3-none-any.whl size=38943 sha256=67a8dd0d1b500cd43790a2dc8786c78ec0a12deff6cd461a066fa68d5b91c6bc\n","  Stored in directory: /root/.cache/pip/wheels/e8/31/d6/c2ea1dd468ff9d67b94bf63a4fb4590337ac6af531b1d04aae\n","Successfully built segm mmcv python-hostlist\n","Installing collected packages: yapf, addict, timm, python-hostlist, mmsegmentation, mmcv, einops, segm\n","Successfully installed addict-2.4.0 einops-0.4.1 mmcv-1.3.8 mmsegmentation-0.14.1 python-hostlist-1.21 segm-0.0.1 timm-0.4.12 yapf-0.32.0\n","Collecting PyYAML\n","  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","Installing collected packages: PyYAML\n","Successfully installed PyYAML-6.0\n"]}]},{"cell_type":"markdown","source":["Ora siamo pronti per effettuare una prova di segmentazione semantica. Se dovesse dire \"AttributeError: module 'yaml' has no attribute 'FullLoader'\", allora scommentare la prossima riga di codice ed eseguirla. È infatti un problema della versione di yaml."],"metadata":{"id":"jo2Jjzd669Ui"}},{"cell_type":"code","source":["#set environment variables\n","os.environ['DATASET'] = \"/content/drive/My Drive/Immagine\"\n","#os.environ['FORCE_CUDA'] = \"0\""],"metadata":{"id":"W4AayiIp7s8D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ora proviamo a fare una segmentazione di un'immagine normale"],"metadata":{"id":"N3OqCO17FJv6"}},{"cell_type":"code","source":["%cd /content/drive/My Drive/Segmenter\n","#!python -m segm.inference --model-path \"/content/drive/My Drive/Models/Pre-trained/PASCAL - Seg-L-Mask16/checkpoint.pth\" -i images/ -o segmaps/ \n","!python -m segm.inference --model-path \"/content/drive/My Drive/Models/Pre-trained/PASCAL - Seg-L-Mask16/checkpoint.pth\" -i \"/content/drive/My Drive/Immagine\"  -o segmaps/ "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YdTJHXg1vPE","executionInfo":{"status":"ok","timestamp":1648060669307,"user_tz":-60,"elapsed":24381,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"}},"outputId":"b2c91586-2743-403d-cf90-b1e946196d55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n","100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.56s/it]\n"]}]},{"cell_type":"markdown","source":["Col seguente codice proviamo a spacchettare le immagini dal dataset che mi ha dato il prof e creare un tensore a 4 canali da dare alla nostra versione \"modificata\" del segmenter, sotto la cartella my_segmenter. \n","Tale versione modificata utilizzerà 4 canali invece che 3\n"],"metadata":{"id":"edN_cxrNbnn3"}},{"cell_type":"code","source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","import numpy as np\n","from PIL import Image\n","#dataset_folder = os.path.join(cwd, \"drive/My Drive/Unzipped/\");\n","#dataset_name = os.path.join(dataset_folder, \"brats2019_slice_training_tfrecords/brats2019_slice_training.tfrecords\")\n","dataset_name = os.path.join('/content/drive/My Drive/Unzipped/', \"brats2019_slice_training_tfrecords/brats2019_slice_training.tfrecords\")\n","raw_dataset = tf.data.TFRecordDataset(dataset_name)\n","\n","count = 0\n","for raw_record in raw_dataset: #per capire la struttura del file tfrecord\n","    example = tf.train.Example()\n","    example.ParseFromString(raw_record.numpy())\n","\n","\n","\n","    parsed = tf.train.Example.FromString(raw_record.numpy())\n","    feature = parsed.features.feature\n","\n","    \n","\n","    raw_img_flair_mri = feature['flair_mri'].bytes_list.value[0]\n","    raw_img_seg = feature['seg'].bytes_list.value[0]\n","    raw_img_t1_mri = feature['t1_mri'].bytes_list.value[0]\n","    raw_img_t1ce_mri = feature['t1ce_mri'].bytes_list.value[0]\n","    raw_img_t2_mri = feature['t2_mri'].bytes_list.value[0]\n","\n","    \n","    img_flair_mri = tf.image.decode_png(raw_img_flair_mri)\n","    img_t1_mri = tf.image.decode_png(raw_img_t1_mri)\n","    img_t1ce_mri = tf.image.decode_png(raw_img_t1ce_mri)\n","    img_t2_mri = tf.image.decode_png(raw_img_t2_mri)\n","    img_seg = tf.image.decode_png(raw_img_seg)\n","\n","    array = np.zeros([img_flair_mri.shape[0], img_flair_mri.shape[1], 4], dtype=np.uint8)\n","\n","    array[:, :, 0] = tf.squeeze(img_flair_mri)\n","    array[:, :, 1] = tf.squeeze(img_t1_mri)\n","    array[:, :, 2] = tf.squeeze(img_t1ce_mri)\n","    array[:, :, 3] = tf.squeeze(img_t2_mri)\n","\n","    img = Image.fromarray(array)\n","    img.save('/content/drive/My Drive/Test4Channels/test_4ch_{}.png'.format(count))\n","    count+=1\n","    \n","\n"],"metadata":{"id":"aHrGD2tLb8xI","executionInfo":{"status":"ok","timestamp":1648152625784,"user_tz":-60,"elapsed":209856,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Segmenter/segmenter\n","#!python -m segm.inference --model-path \"/content/drive/My Drive/Models/Pre-trained/PASCAL - Seg-L-Mask16/checkpoint.pth\" -i \"/content/drive/My Drive/Test4Channels\"  -o segmaps/ \n","!python -m segm.inference --model-path \"/content/drive/My Drive/Models/Pre-trained/PASCAL - Seg-L-Mask16/checkpoint.pth\" -i \"/content/drive/My Drive/Dataset/ade20k/ADEChallengeData2016/images/training/\"  -o segmaps/ \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcgnSapxhang","executionInfo":{"status":"ok","timestamp":1648155516137,"user_tz":-60,"elapsed":52477,"user":{"displayName":"Massimo Maitan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12983730475823324538"}},"outputId":"f409acf0-ce9a-4b44-9b47-1720be0cbf71"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Segmenter/segmenter\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n","  0%|                                      | 25/20210 [00:27<6:04:14,  1.08s/it]\n","\n","Aborted!\n"]}]}]}